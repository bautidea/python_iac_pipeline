{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Gonna use postgres, since it runs on the same port and has a similar structure than Redshift.\n",
    "import psycopg2\n",
    "\n",
    "# Gonna use this library to read config file\n",
    "import configparser\n",
    "\n",
    "import json\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading config file.\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('../../AWS credetials/DataPipeline_python_IaC/cluster.config'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using config object to get config parameters.\n",
    "key = config.get('AWS', 'KEY')\n",
    "secret = config.get('AWS', 'SECRET')\n",
    "\n",
    "dwh_cluster_type = config.get('DWH', 'DWH_CLUSTER_TYPE')\n",
    "dwh_num_nodes = config.get('DWH', 'DWH_NUM_NODES')\n",
    "dwh_node_type = config.get('DWH', 'DWH_NODE_TYPE')\n",
    "dwh_cluster_identifier = config.get('DWH', 'DWH_CLUSTER_IDENTIFIER')\n",
    "dwh_db = config.get('DWH', 'DWH_DB')\n",
    "dwh_db_user = config.get('DWH', 'DWH_DB_USER')\n",
    "dwh_db_password = config.get('DWH', 'DWH_DB_PASSWORD')\n",
    "dwh_port = config.get('DWH', 'DWH_PORT')\n",
    "dwh_iam_role_name = config.get('DWH', 'DWH_IAM_ROLE_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to diferent services using boto3.\n",
    "ec2 = boto3.resource('ec2', \n",
    "                     region_name='sa-east-1',\n",
    "                     aws_access_key_id=key,\n",
    "                     aws_secret_access_key = secret\n",
    "                     )\n",
    "\n",
    "s3 = boto3.resource('s3', \n",
    "                     region_name='sa-east-1',\n",
    "                     aws_access_key_id=key,\n",
    "                     aws_secret_access_key = secret\n",
    "                     )\n",
    "\n",
    "iam = boto3.client('iam', \n",
    "                     region_name='sa-east-1',\n",
    "                     aws_access_key_id=key,\n",
    "                     aws_secret_access_key = secret\n",
    "                     )\n",
    "\n",
    "redshift = boto3.client('redshift', \n",
    "                     region_name='sa-east-1',\n",
    "                     aws_access_key_id=key,\n",
    "                     aws_secret_access_key = secret\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allevents_pipe.txt',\n",
       " 'allusers_pipe.txt',\n",
       " 'category_pipe.txt',\n",
       " 'date2008_pipe.txt',\n",
       " 'listings_pipe.txt',\n",
       " 'sales_tab.txt',\n",
       " 'venue_pipe.txt']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaning all my files available in S3.\n",
    "bucket = s3.Bucket('datapipeline-python-iac')\n",
    "\n",
    "log_data_files = [filename.key for filename in bucket.objects.all()]\n",
    "log_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Iam Role ARN, so i can pass Iam access to my cluster.\n",
    "role_arn = iam.get_role(RoleName=dwh_iam_role_name)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my Redshift cluster.\n",
    "try:\n",
    "    response = redshift.create_cluster(\n",
    "        ClusterType = dwh_cluster_type,\n",
    "        NodeType = dwh_node_type,\n",
    "        \n",
    "        # Identifiers and credentials.\n",
    "        DBName = dwh_db,\n",
    "        ClusterIdentifier = dwh_cluster_identifier,\n",
    "        MasterUsername = dwh_db_user,\n",
    "        MasterUserPassword = dwh_db_password,\n",
    "        \n",
    "        # Roles (for s3 acces)\n",
    "        IamRoles = [role_arn]\n",
    "    )\n",
    "# If cluster is already created or there is a problem creating it, exception is raised.\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Available\n"
     ]
    }
   ],
   "source": [
    "# loop to wait till cluster is created.\n",
    "status = redshift.describe_clusters(ClusterIdentifier = dwh_cluster_identifier)['Clusters'][0]['ClusterStatus']\n",
    "\n",
    "while status == 'creating':\n",
    "    status = redshift.describe_clusters(ClusterIdentifier = dwh_cluster_identifier)['Clusters'][0]['ClusterStatus']\n",
    "    if status != 'creating':\n",
    "        print('Cluster Available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>awsuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DBName</td>\n",
       "      <td>pipeline_python_iac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'data-pipeline-python-iac-cluster....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-0bc0d1833e8dfbcb3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Key                                              Value\n",
       "0        NodeType                                          dc2.large\n",
       "1   ClusterStatus                                          available\n",
       "2  MasterUsername                                            awsuser\n",
       "3          DBName                                pipeline_python_iac\n",
       "4        Endpoint  {'Address': 'data-pipeline-python-iac-cluster....\n",
       "5           VpcId                              vpc-0bc0d1833e8dfbcb3"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining a function that takes json values and returns a dataframe, so its easier to read.\n",
    "def pretty_redshift_properties (props):\n",
    "    # Defining keys i want to show.\n",
    "    keys_to_show = ['CusterIdentifier', 'NodeType', 'ClusterStatus', 'MasterUsername', 'DBName', 'Endpoint', 'VpcId']\n",
    "    # Looking for keys in the json items.\n",
    "    x = [(key, value) for key, value in props.items() if key in keys_to_show]\n",
    "    df = pd.DataFrame(data=x, columns=['Key', 'Value'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Getting the json value of cluster properties.    \n",
    "my_cluster_properties = redshift.describe_clusters(ClusterIdentifier = dwh_cluster_identifier)['Clusters'][0]\n",
    "# Passing previous value to my function.\n",
    "pretty_redshift_properties(my_cluster_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all information from the json values, i need all this information in core, to create vpc.\n",
    "dwh_endpoint = my_cluster_properties['Endpoint']['Address']\n",
    "dwh_role_arn = my_cluster_properties['IamRoles'][0]['IamRoleArn']\n",
    "db_name = my_cluster_properties['DBName']\n",
    "db_user = my_cluster_properties['MasterUsername']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-041025bcadc8b904a')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "# Creating security group\n",
    "try:\n",
    "    vpc_id = my_cluster_properties['VpcId']\n",
    "    vpc = ec2.Vpc(id=vpc_id)\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName=defaultSg.group_name,\n",
    "        CidrIp='0.0.0.0/0',\n",
    "        IpProtocol='TCP',\n",
    "        FromPort= int(dwh_port),\n",
    "        ToPort=int(dwh_port)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Connectint to database.\n",
    "    conn = psycopg2.connect(host = dwh_endpoint, dbname = db_name, user = db_user, password = dwh_db_password, port = dwh_port)\n",
    "    conn.set_session(autocommit=True)\n",
    "    \n",
    "    # Creating cursor instance.\n",
    "    cur = conn.cursor()\n",
    "except psycopg2.Error as e:\n",
    "    print('Error: Could not connect to postgre database')\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data model.\n",
    "try:\n",
    "    create_users_query = ('''\n",
    "                         CREATE TABLE users(\n",
    "                             user_id INT NOT NULL DISTKEY SORTKEY,\n",
    "                             username VARCHAR,\n",
    "                             first_name VARCHAR,\n",
    "                             last_name VARCHAR,\n",
    "                             city VARCHAR,\n",
    "                             state VARCHAR,\n",
    "                             email VARCHAR,\n",
    "                             phone VARCHAR,\n",
    "                             like_sport BOOLEAN,\n",
    "                             like_theater BOOLEAN,\n",
    "                             like_concerts BOOLEAN,\n",
    "                             like_jazz BOOLEAN,\n",
    "                             like_classical BOOLEAN,\n",
    "                             like_opera BOOLEAN,\n",
    "                             like_rock BOOLEAN,\n",
    "                             like_vegas BOOLEAN,\n",
    "                             like_broadway BOOLEAN,\n",
    "                             like_musicales BOOLEAN\n",
    "                        )''')    \n",
    "    cur.execute(create_users_query)\n",
    "    \n",
    "    create_venue_query = ('''\n",
    "                          CREATE TABLE venue(\n",
    "                              venue_id INT NOT NULL DISTKEY SORTKEY,\n",
    "                              venue_name VARCHAR,\n",
    "                              venue_city VARCHAR,\n",
    "                              venue_state VARCHAR,\n",
    "                              venue_seats VARCHAR\n",
    "                        )''')\n",
    "    cur.execute(create_venue_query)\n",
    "    \n",
    "    create_category_query = ('''\n",
    "                             CREATE TABLE category(\n",
    "                                 cat_id INT NOT NULL DISTKEY SORTKEY,\n",
    "                                 cat_group VARCHAR,\n",
    "                                 cat_name VARCHAR,\n",
    "                                 cat_desc VARCHAR\n",
    "                            )''')\n",
    "    cur.execute(create_category_query)\n",
    "    \n",
    "    create_date_query = ('''\n",
    "                        CREATE TABLE date(\n",
    "                            date_id INT NOT NULL DISTKEY SORTKEY,\n",
    "                            cal_date DATE NOT NULL,\n",
    "                            day VARCHAR NoT NULL,\n",
    "                            week INT NOT NULL,\n",
    "                            month VARCHAR NOT NULL,\n",
    "                            qtr VARCHAR NOT NULL,\n",
    "                            year VARCHAR NOT NULL,\n",
    "                            holiday BOOLEAN DEFAULT('N')\n",
    "                        )''')\n",
    "    cur.execute(create_date_query)\n",
    "    \n",
    "    create_event_query = ('''\n",
    "                        CREATE TABLE event(\n",
    "                            event_id INT NOT NULL DISTKEY,\n",
    "                            venue_id INT NOT NULL,\n",
    "                            cat_id INT NOT NULL,\n",
    "                            date_id INT NOT NULL,\n",
    "                            event_name VARCHAR,\n",
    "                            start_time TIMESTAMP\n",
    "                        )''')\n",
    "    cur.execute(create_event_query)\n",
    "    \n",
    "    create_listing_query = ('''\n",
    "                            CREATE TABLE listing(\n",
    "                                list_id INT NOT NULL DISTKEY,\n",
    "                                seller_id INT NOT NULL,\n",
    "                                event_id INT NOT NULL,\n",
    "                                date_id INT NOT NULL,\n",
    "                                num_tickets INT NOT NULL,\n",
    "                                price_per_ticket DECIMAL(8,2),\n",
    "                                total_price DECIMAL(8,2),\n",
    "                                list_time TIMESTAMP\n",
    "                            )''')\n",
    "    cur.execute(create_listing_query)\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print('Error: issue creating table')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since i have already my data on S3, im going to transfer it to Redshift.\n",
    "# For that the following function was created, it takes table_name and the S3 file url\n",
    "# then fetch all data and transform it into a DataFrame.\n",
    "def get_df (table_name, s3_url, credential='aws_iam_role=arn:aws:iam::961251108862:role/redshift-S3-acces', delimiter='|', region='sa-east-1'):\n",
    "    try:\n",
    "        cur.execute('''\n",
    "                    COPY %s FROM '%s'\n",
    "                    CREDENTIALS '%s'\n",
    "                    DELIMITER '%s'\n",
    "                    region '%s'\n",
    "                    '''\n",
    "                    %(table_name, \n",
    "                    s3_url, \n",
    "                    credential, \n",
    "                    delimiter, \n",
    "                    region)\n",
    "                    )\n",
    "        # Selecting all data from table.\n",
    "        cur.execute('SELECT * FROM %s' %(table_name))\n",
    "        \n",
    "        # Retrieving all data from table\n",
    "        result = cur.fetchall()\n",
    "        \n",
    "        # Getting column names\n",
    "        cols = []\n",
    "        for etl in cur.description:\n",
    "            cols.append(etl[0])\n",
    "        \n",
    "        # Returning Data Frame.\n",
    "        return pd.DataFrame(data=result, columns=cols)\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>like_sport</th>\n",
       "      <th>like_theater</th>\n",
       "      <th>like_concerts</th>\n",
       "      <th>like_jazz</th>\n",
       "      <th>like_classical</th>\n",
       "      <th>like_opera</th>\n",
       "      <th>like_rock</th>\n",
       "      <th>like_vegas</th>\n",
       "      <th>like_broadway</th>\n",
       "      <th>like_musicales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4555</th>\n",
       "      <td>8053</td>\n",
       "      <td>GSN60KXT</td>\n",
       "      <td>Beverly</td>\n",
       "      <td>Fowler</td>\n",
       "      <td>Claremont</td>\n",
       "      <td>MB</td>\n",
       "      <td>pharetra@elementumategestas.edu</td>\n",
       "      <td>(351) 175-0759</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41750</th>\n",
       "      <td>38385</td>\n",
       "      <td>JUK79IRO</td>\n",
       "      <td>Gage</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>Rock Springs</td>\n",
       "      <td>KY</td>\n",
       "      <td>amet.ante@porttitorscelerisqueneque.edu</td>\n",
       "      <td>(170) 918-0467</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14869</th>\n",
       "      <td>17603</td>\n",
       "      <td>WXY84HLN</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Kinney</td>\n",
       "      <td>College Park</td>\n",
       "      <td>NY</td>\n",
       "      <td>gravida@eumetusIn.org</td>\n",
       "      <td>(935) 311-1468</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  username first_name last_name          city state  \\\n",
       "4555      8053  GSN60KXT    Beverly    Fowler     Claremont    MB   \n",
       "41750    38385  JUK79IRO       Gage   Sanders  Rock Springs    KY   \n",
       "14869    17603  WXY84HLN  Stephanie    Kinney  College Park    NY   \n",
       "\n",
       "                                         email           phone like_sport  \\\n",
       "4555           pharetra@elementumategestas.edu  (351) 175-0759       None   \n",
       "41750  amet.ante@porttitorscelerisqueneque.edu  (170) 918-0467       None   \n",
       "14869                    gravida@eumetusIn.org  (935) 311-1468       None   \n",
       "\n",
       "      like_theater like_concerts like_jazz like_classical like_opera  \\\n",
       "4555         False          True      True           True       None   \n",
       "41750         None         False      None           True       None   \n",
       "14869        False         False      None          False       None   \n",
       "\n",
       "      like_rock like_vegas like_broadway like_musicales  \n",
       "4555       None       None         False           None  \n",
       "41750      None       True         False           None  \n",
       "14869     False       None          None           True  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users table.\n",
    "get_df('users', 's3://datapipeline-python-iac/allusers_pipe.txt').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>4146</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>2173</td>\n",
       "      <td>Pepe Aguilar</td>\n",
       "      <td>2008-12-13 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>1396</td>\n",
       "      <td>211</td>\n",
       "      <td>6</td>\n",
       "      <td>2025</td>\n",
       "      <td>Seven Brides for Seven Brothers</td>\n",
       "      <td>2008-07-18 14:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>6938</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>2123</td>\n",
       "      <td>Dave Stewart</td>\n",
       "      <td>2008-10-24 19:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_id  venue_id  cat_id  date_id                       event_name  \\\n",
       "3403      4146        99       9     2173                     Pepe Aguilar   \n",
       "2183      1396       211       6     2025  Seven Brides for Seven Brothers   \n",
       "6117      6938        54       9     2123                     Dave Stewart   \n",
       "\n",
       "              start_time  \n",
       "3403 2008-12-13 19:00:00  \n",
       "2183 2008-07-18 14:00:00  \n",
       "6117 2008-10-24 19:00:00  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# events table.\n",
    "get_df('event', 's3://datapipeline-python-iac/allevents_pipe.txt').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>cat_group</th>\n",
       "      <th>cat_name</th>\n",
       "      <th>cat_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Shows</td>\n",
       "      <td>Plays</td>\n",
       "      <td>All non-musical theatre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>National Football League</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Sports</td>\n",
       "      <td>MLS</td>\n",
       "      <td>Major League Soccer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat_id cat_group cat_name                  cat_desc\n",
       "8       7     Shows    Plays   All non-musical theatre\n",
       "1       3    Sports      NFL  National Football League\n",
       "7       5    Sports      MLS       Major League Soccer"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# caregory table.\n",
    "get_df('category', 's3://datapipeline-python-iac/category_pipe.txt').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>cal_date</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>qtr</th>\n",
       "      <th>year</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2104</td>\n",
       "      <td>2008-10-05</td>\n",
       "      <td>SU</td>\n",
       "      <td>41</td>\n",
       "      <td>OCT</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2122</td>\n",
       "      <td>2008-10-23</td>\n",
       "      <td>TH</td>\n",
       "      <td>43</td>\n",
       "      <td>OCT</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2058</td>\n",
       "      <td>2008-08-20</td>\n",
       "      <td>WE</td>\n",
       "      <td>34</td>\n",
       "      <td>AUG</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_id    cal_date day  week month qtr  year  holiday\n",
       "288     2104  2008-10-05  SU    41   OCT   4  2008    False\n",
       "326     2122  2008-10-23  TH    43   OCT   4  2008    False\n",
       "115     2058  2008-08-20  WE    34   AUG   3  2008    False"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date table.\n",
    "get_df('date', 's3://datapipeline-python-iac/date2008_pipe.txt').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>list_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>num_tickets</th>\n",
       "      <th>price_per_ticket</th>\n",
       "      <th>total_price</th>\n",
       "      <th>list_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7689</th>\n",
       "      <td>15755</td>\n",
       "      <td>28725</td>\n",
       "      <td>7295</td>\n",
       "      <td>1955</td>\n",
       "      <td>9</td>\n",
       "      <td>34.00</td>\n",
       "      <td>306.00</td>\n",
       "      <td>2008-05-09 05:52:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15116</th>\n",
       "      <td>31949</td>\n",
       "      <td>4330</td>\n",
       "      <td>7310</td>\n",
       "      <td>2037</td>\n",
       "      <td>6</td>\n",
       "      <td>37.00</td>\n",
       "      <td>222.00</td>\n",
       "      <td>2008-07-30 07:58:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185830</th>\n",
       "      <td>220928</td>\n",
       "      <td>43976</td>\n",
       "      <td>809</td>\n",
       "      <td>1859</td>\n",
       "      <td>1</td>\n",
       "      <td>1980.00</td>\n",
       "      <td>1980.00</td>\n",
       "      <td>2008-02-02 09:13:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        list_id  seller_id  event_id  date_id  num_tickets price_per_ticket  \\\n",
       "7689      15755      28725      7295     1955            9            34.00   \n",
       "15116     31949       4330      7310     2037            6            37.00   \n",
       "185830   220928      43976       809     1859            1          1980.00   \n",
       "\n",
       "       total_price           list_time  \n",
       "7689        306.00 2008-05-09 05:52:11  \n",
       "15116       222.00 2008-07-30 07:58:54  \n",
       "185830     1980.00 2008-02-02 09:13:56  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listings table.\n",
    "get_df('listing', 's3://datapipeline-python-iac/listings_pipe.txt').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_id</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>venue_city</th>\n",
       "      <th>venue_state</th>\n",
       "      <th>venue_seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>301</td>\n",
       "      <td>Ellie Caulkins Opera House</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>14</td>\n",
       "      <td>Buck Shaw Stadium</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>34</td>\n",
       "      <td>Rose Garden</td>\n",
       "      <td>Portland</td>\n",
       "      <td>OR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     venue_id                  venue_name   venue_city venue_state venue_seats\n",
       "195       301  Ellie Caulkins Opera House       Denver          CO           0\n",
       "98         14           Buck Shaw Stadium  Santa Clara          CA           0\n",
       "106        34                 Rose Garden     Portland          OR           0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# venue table.\n",
    "get_df('venue', 's3://datapipeline-python-iac/venue_pipe.txt').sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Deleted\n"
     ]
    }
   ],
   "source": [
    "# Now we need to close connection with cluster, since the cluster is no use from now on\n",
    "# im going to delete it.\n",
    "redshift.delete_cluster(ClusterIdentifier = dwh_cluster_identifier, SkipFinalClusterSnapshot = True)\n",
    "print('Cluster Deleted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dhdsblend2021')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9689ec58c8207ae0e5df44f3c0da8809222a7a4816f0f8cce8ef27c7a9266816"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
